{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d001f6d8",
   "metadata": {},
   "source": [
    "### Model\n",
    "A large language model (LLM) serves as the interface for the AI's capabilities. The LLM processes plain text input and generates text output, forming the core functionality needed to complete various tasks. When integrated with LangChain, the LLM becomes a powerful tool, providing the foundational structure necessary for building and deploying sophisticated AI applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b6892",
   "metadata": {},
   "source": [
    "### Chat model\n",
    "\n",
    "To enable the LLM to work with LangChain, converting the LLM into a chat model, which allows the LLM to integrate seamlessly with LangChain's framework for creating interactive and dynamic AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e2133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm rnj-1, developed by Essential AI to be a helpful assistant. How can I assist you today?\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Initialize the Ollama model (make sure Ollama is running locally)\n",
    "# with Ollama running, use the command line to start a model -> Ollama run <model_name>\n",
    "\n",
    "# Run: ollama run mistral (best for complex logic)\n",
    "llm = OllamaLLM(\n",
    "    model=\"rnj-1:8b-cloud\",  # Excellent for complex reasoning and logic\n",
    "    temperature=0.7, # Higher temperature for more creative responses,  # Lower temperature for more deterministic responses\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "llm.invoke(\"hi,Who are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978837b",
   "metadata": {},
   "source": [
    "### Chat message\n",
    "\n",
    "The chat model takes a list of messages as input and returns a new message. All messages have both a role and a content property.  Here's a list of the most commonly used types of messages:\n",
    "\n",
    "- `SystemMessage`: Use this message type to prime AI behavior.  This message type is  usually passed in as the first in a sequence of input messages.\n",
    "- `HumanMessage`: This message type represents a message from a person interacting with the chat model.\n",
    "- `AIMessage`: This message type, which can be either text or a request to invoke a tool, represents a message from the chat model.\n",
    "\n",
    "You can find more message types at [LangChain built-in message types](https://python.langchain.com/v0.2/docs/how_to/custom_chat_model/#messages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d746e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = llm.invoke(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful AI bot that assists a user in choosing the perfect book to read in one short sentence\"),\n",
    "        HumanMessage(content=\"I enjoy mystery novels, what should I read?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5356f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('System: You are a helpful AI bot that assists a user in choosing the perfect book to read in one short sentence\\n'\n",
      " 'Human: I enjoy mystery novels, what should I read?\\n'\n",
      " 'AI: How about \"The Girl with the Dragon Tattoo\" by Stieg Larsson for a gripping mystery?')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(msg , width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = llm.invoke(\n",
    "    [\n",
    "        SystemMessage(content=\"\"\"You are a assistant that helps students learn physics concepts by providing clear and \n",
    "                      concise explanations and you will describe in detail with Thai language\"\"\"),\n",
    "        HumanMessage(content=\"\"\"แก้โจทย์ปัญหาฟิสิกส์: แสงความยาวคลื่น 480 นาโนเมตร ส่องตั้งฉากผ่านสลิตคู่ที่มีระยะห่างระหว่างช่อง 1 ไมโครเมตร \n",
    "                     จงหาว่าจำนวนแถบสว่างที่เป็นไปได้มากที่สุดจะมีกี่แถบ\"\"\"),\n",
    "        AIMessage(content=\"Sure! Here's the detailed explanation in Thai: ...\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02861220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('อีกครั้งยินดีให้คำแนะนำในการแก้โจทย์ปัญหาฟิสิกส์ที่เกี่ยวข้องกับการส่องตั้งฉากผ่านสลิตคู่ (Double Slit Diffraction) ด้วยแสงคลื่นหนึ่งหน่วย\\n'\n",
      " '\\n'\n",
      " '**ขั้นตอนในการแก้โจทย์ปัญหานี้:**\\n'\n",
      " '\\n'\n",
      " '1. **กำหนดค่าของตัวแปรที่กำหนดในโจทย์ปัญหา:**\\n'\n",
      " '   - ระยะห่างระหว่างช่องของสลิตคู่ (d) = 1 ไมโครเมตร = $1 \\\\times 10^{-6}$ เมตร\\n'\n",
      " '   - ความยาวคลื่นของแสง (λ) = 480 นาโนเมตร = $480 \\\\times 10^{-9}$ เมตร\\n'\n",
      " '\\n'\n",
      " '2. **ใช้สูตรการหาส่วนแบ่งสว่างที่เกิดจากการส่องตั้งฉากผ่านสลิตคู่:**\\n'\n",
      " '   - สูตรคือ $a\\\\sin(\\\\theta) = m\\\\lambda$, โดยที่ $m = 0, \\\\pm1, \\\\pm2,...$\\n'\n",
      " '   - โดยที่ $\\\\theta$ คือมุมที่เกิดจากการส่องตั้งฉากผ่านสลิตคู่\\n'\n",
      " '\\n'\n",
      " '3. **หาค่าของ $\\\\sin(\\\\theta)$ จากสูตร:**\\n'\n",
      " '   - จากสูตร $a\\\\sin(\\\\theta) = m\\\\lambda$, เราสามารถหาค่าของ $\\\\sin(\\\\theta)$ ได้เป็น $\\\\sin(\\\\theta) = \\\\frac{m\\\\lambda}{a}$\\n'\n",
      " '   - โดยที่ $m$ คือจำนวนแถบสว่างที่เป็นไปได้\\n'\n",
      " '\\n'\n",
      " '4. **หาค่าของ $m$ จากสูตร:**\\n'\n",
      " '   - จากสูตร $\\\\sin(\\\\theta) = \\\\frac{m\\\\lambda}{a}$, เราสามารถหาค่าของ $m$ ได้เป็น $m = \\\\frac{a\\\\sin(\\\\theta)}{\\\\lambda}$\\n'\n",
      " '   - โดยที่ $\\\\sin(\\\\theta)$ คือค่าที่ได้จากข้อ 3\\n'\n",
      " '\\n'\n",
      " '5. **หาค่าของ $m$ จากข้อมูลที่กำหนดในโจทย์ปัญหา:**\\n'\n",
      " '   - จากข้อมูลที่กำหนดในโจทย์ปัญหา, เราสามารถหาค่าของ $m$ ได้เป็น $m = \\\\frac{1 \\\\times 10^{-6} \\\\times \\\\sin(90^{\\\\circ})}{480 \\\\times 10^{-9}} = '\n",
      " '\\\\frac{1 \\\\times 10^{-6}}{480 \\\\times 10^{-9}} = \\\\frac{1}{480} \\\\approx 2.083$\\n'\n",
      " '   - แต่เนื่องจาก $m$ ต้องเป็นจำนวนเต็ม, ดังนั้น $m$ ต้องเป็นจำนวนเต็มที่มากที่สุดที่น้อยกว่าหรือเท่ากับ 2.083\\n'\n",
      " '\\n'\n",
      " '**สรุปคำตอบ:**\\n'\n",
      " '\\n'\n",
      " 'จำนวนแถบสว่างที่เป็นไปได้มากที่สุดคือ 2 แถบ\\n'\n",
      " '\\n'\n",
      " '**คำตอบสุดท้าย:**\\n'\n",
      " '\\n'\n",
      " 'จำนวนแถบสว่างที่เป็นไปได้มากที่สุดคือ \\\\boxed{2} แถบ')\n"
     ]
    }
   ],
   "source": [
    "pprint(msg , width=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49c3e8f",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "\n",
    "Prompt templates help translate user input and parameters into instructions for a language model. You can use prompt templates to guide a model's response, helping the model understand the context and generate relevant and coherent language-based output.\n",
    "\n",
    "Next, explore several different types of prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Use these prompt templates to format a single string. These templates are generally used for simpler inputs.\n",
    "\n",
    "prop_problem_template = PromptTemplate(\n",
    "    input_variables=[\"thinhs\"],\n",
    "    template=\"ถ้ามีลูกบอลที่แตกต่างกันจำนวน {thinhs} ลูก ถ้าหยิบออกมาจากกล่อง 2 ลูก จะมีกี่วิธีในการหยิบ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "002b5416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='ถ้ามีลูกบอลที่แตกต่างกันจำนวน 5 ลูก ถ้าหยิบออกมาจากกล่อง 2 ลูก จะมีกี่วิธีในการหยิบ?')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_problem_template.invoke({\"thinhs\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f958bb",
   "metadata": {},
   "source": [
    "#### Chat prompt templates\n",
    "\n",
    "You can use these prompt templates to format a list of messages. These \"templates\" consist of lists of templates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fe9de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatPromptValue(messages=[SystemMessage(content='You are a assistant that helps students learn math concepts by providing clear and \\n            concise explanations and you will describe in detail with Thai language', additional_kwargs={}, response_metadata={}), HumanMessage(content='ถ้ามีลูกบอลที่แตกต่างกันจำนวน 5 ลูก ถ้าหยิบออกมาจากกล่อง 2 ลูก จะมีกี่วิธีในการหยิบ?', additional_kwargs={}, response_metadata={})])\n"
     ]
    }
   ],
   "source": [
    "# Import the ChatPromptTemplate class from langchain_core.prompts module\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a ChatPromptTemplate with a list of message tuples\n",
    "# Each tuple contains a role (\"system\" or \"user\") and the message content\n",
    "# The system message sets the behavior of the assistant\n",
    "# The user message includes a variable placeholder {topic} that will be replaced later\n",
    "Chat_prompt = ChatPromptTemplate.from_messages([\n",
    " (\"system\", \"\"\"You are a assistant that helps students learn math concepts by providing clear and \n",
    "            concise explanations and you will describe in detail with Thai language\"\"\"),\n",
    " (\"user\", \"ถ้ามีลูกบอลที่แตกต่างกันจำนวน {thinhs} ลูก ถ้าหยิบออกมาจากกล่อง 2 ลูก จะมีกี่วิธีในการหยิบ?\")\n",
    "])\n",
    "\n",
    "# Create a dictionary with the variable to be inserted into the template\n",
    "# The key \"topic\" matches the placeholder name in the user message\n",
    "input_ = {\"thinhs\": 5}\n",
    "\n",
    "# Format the chat template with our input values\n",
    "# This replaces {topic} with \"cats\" in the user message\n",
    "# The result will be a formatted chat message structure ready to be sent to a model\n",
    "\n",
    "pprint(Chat_prompt.invoke(input_), width=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627cff1",
   "metadata": {},
   "source": [
    "####  MessagesPlaceholder\n",
    "\n",
    "You can use the MessagesPlaceholder prompt template to add a list of messages in a specific location. In `ChatPromptTemplate.from_messages`, you saw how to format two messages, with each message as a string. But what if you want the user to supply a list of messages that you would slot into a particular spot? You can use `MessagesPlaceholder` for this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af6d67b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"You are a helpful assistant\"),\n",
    "MessagesPlaceholder(\"msgs\")  # This will be replaced with one or more messages\n",
    "])\n",
    "prompt.messages[0].prompt # Access the system message template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73fb3667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the day after Tuesday?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create an input dictionary where the key matches the MessagesPlaceholder name\n",
    "# The value is a list of message objects that will replace the placeholder\n",
    "# Here we're adding a single HumanMessage asking about the day after Tuesday\n",
    "input_ = {\"msgs\": [HumanMessage(content=\"What is the day after Tuesday?\")]}\n",
    "\n",
    "# Format the chat template with our input dictionary\n",
    "# This replaces the MessagesPlaceholder with the HumanMessage in our input\n",
    "# The result will be a formatted chat structure with a system message and our human message\n",
    "prompt.invoke(input_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f110cdc8",
   "metadata": {},
   "source": [
    "### Create Chain to thing\n",
    "You can wrap the prompt and the chat model and pass them into a chain, which can invoke the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8401e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ถ้าหยิบลูกบอลออกมา 2 ลูกจากทั้งหมด 5 ลูกที่แตกต่างกัน '\n",
      " 'โดยไม่สนใจลำดับของการหยิบ จะใช้การคำนวณ組合 (Combination) ซึ่งมีสูตรดังนี้:\\n'\n",
      " '\\n'\n",
      " 'C(n, k) = n! / [k! * (n-k)!]\\n'\n",
      " '\\n'\n",
      " 'โดยที่:\\n'\n",
      " '- n เป็นจำนวนทั้งหมดของลูกบอล (ในกรณีนี้คือ 5)\\n'\n",
      " '- k เป็นจำนวนที่หยิบออกมา (ในกรณีนี้คือ 2)\\n'\n",
      " '- ! คือฟังก์ชันแฟกทอเรียล (factorial)\\n'\n",
      " '\\n'\n",
      " 'ดังนั้น:\\n'\n",
      " 'C(5, 2) = 5! / [2! * (5-2)!]\\n'\n",
      " 'C(5, 2) = (5 * 4 * 3 * 2 * 1) / [(2 * 1) * (3 * 2 * 1)]\\n'\n",
      " 'C(5, 2) = (120) / [(2) * (6)]\\n'\n",
      " 'C(5, 2) = 120 / 12\\n'\n",
      " 'C(5, 2) = 10\\n'\n",
      " '\\n'\n",
      " 'ดังนั้นจะมีทั้งหมด 10 วิธีในการหยิบลูกบอลออกมา 2 ลูกจาก 5 ลูกที่แตกต่างกัน')\n"
     ]
    }
   ],
   "source": [
    "chain = prop_problem_template | llm\n",
    "pprint(chain.invoke({\"thinhs\": 5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c4cad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ในการหาจำนวนวิธีในการหยิบลูกบอลออกมาจากกล่อง 2 ลูก '\n",
      " 'โดยมีลูกบอลที่แตกต่างกันจำนวน 5 ลูก เราจะใช้หลักการของการจัดหมู่ '\n",
      " '(Combinations) ซึ่งเป็นการจัดเรียงที่ไม่คำนึงถึงลำดับของสมาชิก\\n'\n",
      " '\\n'\n",
      " 'สูตรการหาจำนวนวิธีในการหยิบลูกบอลออกมาจากกล่อง 2 ลูก คือ:\\n'\n",
      " '\\n'\n",
      " 'C(n, k) = n! / (k!(n-k)!)\\n'\n",
      " '\\n'\n",
      " 'โดยที่:\\n'\n",
      " '- n คือจำนวนลูกบอลทั้งหมด (ในกรณีนี้คือ 5 ลูก)\\n'\n",
      " '- k คือจำนวนลูกบอลที่หยิบออกมา (ในกรณีนี้คือ 2 ลูก)\\n'\n",
      " '\\n'\n",
      " 'แทนค่าลงในสูตร:\\n'\n",
      " '\\n'\n",
      " 'C(5, 2) = 5! / (2!(5-2)!)\\n'\n",
      " 'C(5, 2) = 5! / (2!3!)\\n'\n",
      " 'C(5, 2) = (5×4×3×2×1) / ((2×1)(3×2×1))\\n'\n",
      " 'C(5, 2) = 120 / (2×6)\\n'\n",
      " 'C(5, 2) = 120 / 12\\n'\n",
      " 'C(5, 2) = 10\\n'\n",
      " '\\n'\n",
      " 'ดังนั้น จำนวนวิธีในการหยิบลูกบอลออกมาจากกล่อง 2 ลูก '\n",
      " 'จากลูกบอลที่แตกต่างกันจำนวน 5 ลูก คือ 10 วิธี')\n"
     ]
    }
   ],
   "source": [
    "chain = Chat_prompt | llm\n",
    "pprint(chain.invoke({\"thinhs\": 5}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
